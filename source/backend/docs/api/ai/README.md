# ğŸ¤– MEGAHUB AI Infrastructure - API Documentation (O3 Ready)

## Vue d'Ensemble

L'infrastructure AI MEGAHUB est architecturÃ©e en **4 apps spÃ©cialisÃ©es** suivant le principe de responsabilitÃ© unique, permettant une gestion complÃ¨te des jobs IA avec monitoring, quotas et **support natif O3/GPT-4.1**.

### ğŸš€ NouveautÃ©s 2024
- âœ… **Support O3 complet** : ModÃ¨les de raisonnement avancÃ© avec auto-configuration
- âœ… **GPT-4.1 Enhanced** : Version amÃ©liorÃ©e de GPT-4 avec contexte large
- âœ… **Auto-configuration intelligente** : ParamÃ¨tres adaptÃ©s automatiquement selon le modÃ¨le
- âœ… **Cost optimization** : Recommandations intelligentes par complexitÃ© de tÃ¢che
- âœ… **Quality metrics** : MÃ©triques de performance par gÃ©nÃ©ration
- âœ… **Model comparison** : Analytics comparatifs O3 vs legacy

### Base URLs
```
https://backoffice.humari.fr/ai/                 # Hub principal
https://backoffice.humari.fr/ai/providers/       # Providers et credentials
https://backoffice.humari.fr/ai/openai/          # OpenAI O3/GPT-4.1
https://backoffice.humari.fr/ai/usage/           # Usage et mÃ©triques
```

---

## ğŸ“ Architecture des Apps

### ğŸ¯ ai_core - Hub Central
**ResponsabilitÃ©** : Hub central des jobs IA, types de jobs, statuts
- CRUD des jobs IA principales
- Types de jobs et catÃ©gories  
- Statuts et workflow de progression
- **Nouveau** : Support mÃ©tadonnÃ©es O3/GPT-4.1
- Dashboard central avec mÃ©triques cross-providers

[ğŸ“– Documentation ComplÃ¨te](./core.md)

### ğŸ”Œ ai_providers - Providers & Quotas  
**ResponsabilitÃ©** : Gestion providers, credentials sÃ©curisÃ©es, quotas
- Providers IA disponibles (OpenAI, Anthropic, Google)
- Credentials chiffrÃ©es par company avec Fernet
- Quotas et limites par provider
- **Nouveau** : Quotas spÃ©cialisÃ©s O3 (coÃ»t Ã©levÃ©)
- Test de connexion et monitoring health

[ğŸ“– Documentation ComplÃ¨te](./providers.md)

### ğŸŸ¢ ai_openai - OpenAI Integration (O3 Enhanced)
**ResponsabilitÃ©** : IntÃ©gration spÃ©cialisÃ©e OpenAI multi-gÃ©nÃ©ration
- **Support O3/O3-mini** : ModÃ¨les de raisonnement avec `reasoning_effort`
- **Support GPT-4.1** : Version enhanced avec tempÃ©rature crÃ©ative
- **Auto-configuration** : ParamÃ¨tres adaptÃ©s par modÃ¨le automatiquement
- **Cost tracking** : CoÃ»ts prÃ©cis par gÃ©nÃ©ration avec alertes
- Chat completions unifiÃ©es et assistants avancÃ©s
- **Conversion intelligente** : Messages legacy â†’ structured automatique

[ğŸ“– Documentation ComplÃ¨te](./openai.md)

### ğŸ“Š ai_usage - Usage & Alertes (Enhanced)
**ResponsabilitÃ©** : Tracking usage, coÃ»ts, mÃ©triques, alertes
- Usage dÃ©taillÃ© par job et provider avec prÃ©cision 6 dÃ©cimales
- **Nouveau** : MÃ©triques qualitÃ© O3 vs legacy
- **Nouveau** : Comparaison performance modÃ¨les avec ROI
- SystÃ¨me d'alertes quota/budget enhanced
- Analytics et recommandations automatiques
- Export CSV/Excel avec filtres avancÃ©s

[ğŸ“– Documentation ComplÃ¨te](./usage.md)

---

## ğŸ”‘ Authentification

**Toutes les APIs** requiÃ¨rent :
```bash
Authorization: Bearer {jwt_token}
X-Brand-ID: {brand_id}  # Scope automatique par brand
```

**Brand Middleware** : Le systÃ¨me utilise automatiquement `request.current_brand` depuis le middleware, plus besoin de gÃ©rer manuellement les headers de brand.

---

## ğŸš€ Quick Start O3

### 1. Chat Completion O3 Simple
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "Analyse ce contenu marketing de faÃ§on approfondie"}
  ],
  "model": "o3",
  "reasoning_effort": "high",
  "max_completion_tokens": 2000
}
```

### 2. O3-Mini pour Optimisation CoÃ»t
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "RÃ©sume cet article SEO"}
  ],
  "model": "o3-mini",
  "reasoning_effort": "medium",
  "max_completion_tokens": 500
}
```

### 3. GPT-4.1 pour CrÃ©ativitÃ©
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "Ã‰cris un article de blog engageant sur l'IA"}
  ],
  "model": "gpt-4.1",
  "temperature": 1.0,
  "max_completion_tokens": 5000
}
```

### 4. Recommandation Automatique
```bash
POST /ai/openai/recommend_model/
{
  "task_description": "Analyser 20 pages de contenu technique",
  "complexity_score": 0.8,
  "budget_constraint": 0.6,
  "quality_requirement": 0.9
}
```

---

## ğŸ¯ Endpoints Rapides

### Jobs IA de Base
```http
GET    /ai/jobs/                    # Liste tous les jobs IA
POST   /ai/jobs/                    # CrÃ©er nouveau job IA
GET    /ai/jobs/{id}/               # DÃ©tail job IA
POST   /ai/jobs/{id}/cancel/        # Annuler job
GET    /ai/jobs/dashboard/          # Dashboard jobs IA
GET    /ai/job-types/               # Types de jobs disponibles
```

### OpenAI O3/GPT-4.1
```http
GET    /ai/openai/chat/             # ğŸ†• ModÃ¨les avec spÃ©cificitÃ©s
POST   /ai/openai/chat/             # ğŸ†• Chat universal multi-modÃ¨les
GET    /ai/openai/jobs/             # Jobs OpenAI avec mÃ©triques
GET    /ai/openai/completion/job_result/?job_id=xyz  # RÃ©sultat job
POST   /ai/openai/recommend_model/  # ğŸ†• Recommandation intelligente
```

### Usage & Analytics Enhanced
```http
GET    /ai/usage/dashboard/?days=7  # Dashboard usage
GET    /ai/usage/model_comparison/  # ğŸ†• Comparaison O3 vs legacy
GET    /ai/usage/cost_breakdown/    # Breakdown coÃ»ts dÃ©taillÃ©
GET    /ai/usage/efficiency/        # ğŸ†• Analyse d'efficacitÃ© modÃ¨les
GET    /ai/usage/trends/            # ğŸ†• Tendances temporelles
GET    /ai/alerts/                  # Alertes usage
```

### Providers & Credentials
```http
GET    /ai/providers/               # Providers disponibles
GET    /ai/credentials/quota_status/?provider=openai  # Statut quota
POST   /ai/credentials/test_connection/  # Tester connexion
GET    /ai/providers/health/        # ğŸ†• Health check providers
```

---

## ğŸ“ˆ Workflow Typique O3

### 1. Analyse Complexe avec O3
```bash
# Ã‰tape 1: CrÃ©er job d'analyse
POST /ai/openai/chat/
{
  "model": "o3",
  "reasoning_effort": "high",
  "messages": [
    {
      "role": "developer", 
      "content": [{"type": "text", "text": "Tu es un expert SEO"}]
    },
    {
      "role": "user",
      "content": [{"type": "text", "text": "Analyse approfondie de ce site..."}]
    }
  ],
  "max_completion_tokens": 3000
}

# Ã‰tape 2: Suivre progression (si async)
GET /ai/jobs/{id}/

# Ã‰tape 3: RÃ©cupÃ©rer rÃ©sultat
GET /ai/openai/completion/job_result/?job_id=ai_job_abc123
```

### 2. Optimisation CoÃ»t avec O3-Mini
```bash
# MÃªme workflow mais modÃ¨le optimisÃ©
POST /ai/openai/chat/
{
  "model": "o3-mini",
  "reasoning_effort": "medium",  # Plus rapide
  "max_completion_tokens": 1000  # LimitÃ© pour coÃ»t
}
```

### 3. Monitoring et Optimisation
```bash
# Analyser usage par modÃ¨le
GET /ai/usage/model_comparison/?models=o3,o3-mini,gpt-4o&days=30

# VÃ©rifier coÃ»ts O3
GET /ai/usage/cost_breakdown/?model=o3

# Alertes budget
GET /ai/alerts/active/
```

---

## ğŸ†• Nouvelles FonctionnalitÃ©s

### Auto-Configuration ModÃ¨les
- **DÃ©tection automatique** : Legacy vs nouvelle gÃ©nÃ©ration
- **ParamÃ¨tres optimaux** : ConfigurÃ©s selon le modÃ¨le
- **Conversion intelligente** : Messages et paramÃ¨tres adaptÃ©s
- **Validation** : Erreurs claires sur paramÃ¨tres incompatibles

### MÃ©triques de QualitÃ©
```json
{
  "model": "o3",
  "quality_indicators": {
    "reasoning_steps": 47,
    "confidence_score": 0.95,
    "complexity_handled": 0.92
  },
  "performance_profile": {
    "speed": "slow",
    "quality": "highest", 
    "cost": "high"
  }
}
```

### Recommandations Intelligentes
- **SÃ©lection automatique** selon task complexity
- **Optimisation coÃ»t** avec alternatives
- **Benchmarks performance** par use case
- **ROI analysis** O3 vs modÃ¨les classiques

---

## ğŸ” Filtres AvancÃ©s

### Filtres Cross-Apps
```http
# Jobs par statut et provider avec gÃ©nÃ©ration
GET /ai/jobs/?status=completed&openai_job__model=o3&openai_job__generation=new

# Usage par pÃ©riode et coÃ»t avec modÃ¨le spÃ©cifique
GET /ai/usage/?created_at__gte=2024-01-01&total_cost__gte=1.00&model_name=o3

# Jobs avec mÃ©triques spÃ©cifiques O3
GET /ai/jobs/?usage__execution_time_seconds__gte=60&openai_job__reasoning_effort=high
```

### Filtres SpÃ©cifiques O3
```http
# Jobs par gÃ©nÃ©ration
GET /ai/jobs/?openai_job__generation=new&openai_job__reasoning_effort=high

# Usage par coÃ»t et efficacitÃ©
GET /ai/usage/?model_name=o3&total_cost__gte=1.00&cost_efficiency__gte=0.8

# Comparaison performance
GET /ai/usage/?generation=new&quality_score__gte=9.0
```

### Recherche Multi-CritÃ¨res
```http
GET /ai/openai/jobs/?generation=new&cost_usd__gte=0.5&quality_score__gte=9.0
GET /ai/usage/?search=analysis&model_name__in=o3,o3-mini,gpt-4.1
```

---

## ğŸ“Š Dashboard Enhanced

### MÃ©triques O3 vs Legacy
```json
{
  "generation_comparison": {
    "new_models": {
      "models": ["o3", "o3-mini", "gpt-4.1"],
      "avg_quality": 9.2,
      "avg_cost": "0.087",
      "avg_execution_time": 4.8,
      "use_cases": ["complex_analysis", "reasoning", "creative_large_context"]
    },
    "legacy_models": {
      "models": ["gpt-4o", "gpt-4-turbo"],
      "avg_quality": 8.7,
      "avg_cost": "0.023",
      "avg_execution_time": 2.1,
      "use_cases": ["general", "speed_optimized", "cost_effective"]
    }
  },
  "recommendations": {
    "cost_optimization": "Use O3-mini for 80% reasoning tasks",
    "quality_premium": "Reserve O3 for complex analysis only",
    "balanced_approach": "GPT-4.1 for creative + large context",
    "default_choice": "GPT-4o for general purpose tasks"
  }
}
```

### Dashboard Usage avec O3
```json
{
  "period": {"days": 30},
  "totals": {
    "jobs": 1247,
    "cost": "456.78",
    "avg_cost_per_job": "0.367"
  },
  "by_generation": [
    {
      "generation": "new",
      "models": ["o3", "o3-mini", "gpt-4.1"],
      "jobs": 234,
      "cost": "298.45",
      "percentage": 65.3,
      "avg_quality": 9.1
    },
    {
      "generation": "legacy", 
      "models": ["gpt-4o", "gpt-4-turbo"],
      "jobs": 1013,
      "cost": "158.33",
      "percentage": 34.7,
      "avg_quality": 8.6
    }
  ],
  "efficiency_insights": {
    "most_cost_effective": "o3-mini",
    "highest_roi": "o3-mini",
    "premium_choice": "o3",
    "fastest": "gpt-4o"
  }
}
```

---

## ğŸš¨ Gestion d'Erreurs Enhanced

### Codes de Statut Standards
- **200**: SuccÃ¨s
- **201**: CrÃ©ation rÃ©ussie  
- **400**: Validation Ã©chouÃ©e (paramÃ¨tres incompatibles)
- **401**: Non authentifiÃ©
- **403**: Permissions insuffisantes / Quota dÃ©passÃ©
- **404**: Ressource non trouvÃ©e
- **429**: Rate limit dÃ©passÃ© (O3 spÃ©cifique)
- **500**: Erreur serveur

### Erreurs SpÃ©cifiques O3
```json
// Temperature sur O3
{
  "error": "O3 models don't support temperature parameter",
  "error_code": "INVALID_PARAMETER_FOR_MODEL",
  "model": "o3",
  "invalid_params": ["temperature"],
  "suggested_params": ["reasoning_effort", "max_completion_tokens"],
  "model_requirements": {
    "required": ["reasoning_effort"],
    "forbidden": ["temperature"],
    "optional": ["max_completion_tokens", "tools"]
  }
}

// Reasoning effort sur legacy
{
  "error": "Model gpt-4o doesn't support reasoning_effort parameter",
  "error_code": "INVALID_PARAMETER_FOR_MODEL", 
  "model": "gpt-4o",
  "invalid_params": ["reasoning_effort"],
  "suggested_params": ["temperature", "max_tokens"]
}

// Budget O3 dÃ©passÃ©
{
  "error": "Estimated cost exceeds daily O3 budget limit",
  "error_code": "O3_BUDGET_EXCEEDED",
  "model": "o3",
  "estimated_cost": "5.67",
  "daily_budget_remaining": "2.34",
  "suggestions": [
    "Use o3-mini for cost optimization",
    "Reduce max_completion_tokens",
    "Use reasoning_effort='low'"
  ],
  "alternatives": ["o3-mini", "gpt-4.1"]
}

// Quota reasoning O3
{
  "error": "Daily reasoning quota exceeded for O3",
  "error_code": "REASONING_QUOTA_EXCEEDED",
  "model": "o3",
  "daily_reasoning_jobs": 50,
  "daily_limit": 50,
  "reset_time": "2024-12-21T00:00:00Z",
  "alternatives": ["o3-mini", "gpt-4.1"]
}
```

### Format d'Erreurs Standard
```json
{
  "detail": "Job type 'invalid_type' non trouvÃ©",
  "error_code": "JOB_TYPE_NOT_FOUND",
  "field_errors": {
    "job_type": ["Ce champ est requis"],
    "priority": ["Doit Ãªtre: low, normal, high, urgent"]
  },
  "suggestions": ["chat_completion", "content_analysis", "text_generation"]
}
```

---

## ğŸ“– Documentation DÃ©taillÃ©e

- **[ğŸ¯ ai_core](./core.md)** - Hub central des jobs IA
- **[ğŸ”Œ ai_providers](./providers.md)** - Providers et credentials sÃ©curisÃ©es  
- **[ğŸŸ¢ ai_openai](./openai.md)** - IntÃ©gration OpenAI O3/GPT-4.1
- **[ğŸ“Š ai_usage](./usage.md)** - Usage, mÃ©triques et alertes enhanced
- **[ğŸ“‹ RÃ©fÃ©rence ComplÃ¨te](./complete-reference.md)** - Tous les endpoints O3
- **[ğŸš€ Exemples](./examples/workflows.md)** - Workflows O3 d'intÃ©gration
- **[âš™ï¸ Migration Guide](./migration/o3-upgrade.md)** - Guide migration O3

---

## ğŸ”§ Setup et Maintenance

### Variables d'Environnement
```bash
# AI Core
AI_DEFAULT_MODEL=gpt-4o
AI_ENABLE_O3=true
AI_O3_DAILY_BUDGET=100.00

# Encryption
AI_ENCRYPTION_KEY=base64_encoded_key

# Quotas
AI_DEFAULT_MONTHLY_QUOTA=1000000
AI_O3_SPECIAL_QUOTA=50000

# Monitoring
AI_ENABLE_ALERTING=true
AI_ALERT_EMAIL=admin@megahub.fr
```

### Commandes de Gestion
```bash
# Setup complet infrastructure AI
python manage.py setup_ai_infrastructure --include-o3

# Test endpoints API avec O3
python manage.py test_ai_endpoints --test-o3 --verbose

# Setup job types avec support O3
python manage.py setup_ai_job_types --include-o3

# Migration vers O3
python manage.py migrate_to_o3_support

# Health check complet
python manage.py ai_health_check --all-providers

# Reset quotas mensuels
python manage.py reset_monthly_ai_quotas

# Audit credentials
python manage.py audit_ai_credentials --rotate-expired
```

### Tests d'IntÃ©gration
```bash
# Test suite complÃ¨te
python manage.py test ai_core ai_providers ai_openai ai_usage

# Test spÃ©cifique O3
python manage.py test ai_openai.tests.test_o3_integration

# Load testing
python manage.py ai_load_test --model=o3 --concurrent=10
```

---

## ğŸ’¡ Bonnes Pratiques

### SÃ©lection de ModÃ¨le Optimal
1. **O3** : Analyse complexe, recherche approfondie, raisonnement critique
2. **O3-mini** : Raisonnement standard, optimisation coÃ»t/qualitÃ©
3. **GPT-4.1** : Contenu crÃ©atif, contexte large, brainstorming
4. **GPT-4o** : TÃ¢ches gÃ©nÃ©rales, rapiditÃ©, efficacitÃ© coÃ»t

### Optimisation des CoÃ»ts O3
1. **reasoning_effort='low'** pour tÃ¢ches simples de raisonnement
2. **Batch processing** pour rÃ©duire les coÃ»ts fixes
3. **Cache intelligent** pour requÃªtes similaires  
4. **Fallback strategy** : O3 â†’ O3-mini â†’ GPT-4.1 â†’ GPT-4o
5. **Budget monitoring** : Alertes Ã  80% du quota quotidien

### Performance et Monitoring
1. **Tracking par gÃ©nÃ©ration** pour analyser ROI prÃ©cis
2. **Alertes prÃ©ventives** sur cost spikes O3
3. **Quality metrics** pour justifier surcoÃ»t premium
4. **Usage patterns** pour optimisation continue
5. **A/B testing** modÃ¨les sur tÃ¢ches similaires

### SÃ©curitÃ©
1. **Rotation credentials** tous les 3 mois minimum
2. **Chiffrement Fernet** pour toutes les clÃ©s API
3. **Audit trail** complet des jobs sensibles
4. **Rate limiting** spÃ©cialisÃ© par modÃ¨le O3
5. **Isolation company** stricte avec middleware

### DÃ©veloppement
1. **Feature flags** pour rollout progressif O3
2. **Backward compatibility** maintenue legacy models
3. **Testing exhaustif** avant production O3
4. **Monitoring alertes** post-dÃ©ploiement
5. **Documentation** tenue Ã  jour avec exemples

---

## ğŸ”® Roadmap

### Q1 2025
- âœ… Support O3/O3-mini complet
- âœ… Auto-configuration intelligente
- âœ… MÃ©triques qualitÃ© avancÃ©es
- ğŸ”„ Fine-tuning automatique selon usage
- ğŸ”„ Multi-provider fallback intelligent

### Q2 2025
- ğŸ“‹ Support Anthropic Claude-4 (si disponible)
- ğŸ“‹ IntÃ©gration Google Gemini Ultra
- ğŸ“‹ Cache distributÃ© Redis pour rÃ©sultats similaires
- ğŸ“‹ API GraphQL pour queries complexes
- ğŸ“‹ Webhooks pour notifications temps rÃ©el

### Q3 2025
- ğŸ“‹ ML-powered cost prediction
- ğŸ“‹ Auto-scaling workers selon charge
- ğŸ“‹ Custom models fine-tunÃ©s MEGAHUB
- ğŸ“‹ Analytics prÃ©dictifs ROI
- ğŸ“‹ Integration Slack/Teams notifications

---

## ğŸ“Š MÃ©triques de Performance

### Objectifs Infrastructure
- **Latence P95** : < 2s pour O3, < 500ms pour legacy
- **DisponibilitÃ©** : 99.9% uptime
- **CoÃ»t par token** : OptimisÃ© par auto-sÃ©lection modÃ¨le
- **PrÃ©cision recommandations** : > 90% satisfaction utilisateur
- **SÃ©curitÃ©** : 0 breach, rotation automatique clÃ©s

### KPIs Business
- **Adoption O3** : 40% des jobs complexes d'ici Q2 2025
- **ROI O3** : JustifiÃ© par qualitÃ© supÃ©rieure vs coÃ»t
- **Cost efficiency** : 25% rÃ©duction coÃ»t total via optimisation
- **User satisfaction** : > 95% sur qualitÃ© suggestions IA
- **Time to value** : < 5min pour premiÃ¨re completion

---

**Version** : 2.0 - Infrastructure O3 Ready, Production Tested âœ…

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2024 - Support O3/GPT-4.1 complet