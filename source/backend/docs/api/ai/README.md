# ü§ñ MEGAHUB AI Infrastructure - API Documentation (O3 Ready)

## Vue d'Ensemble

L'infrastructure AI MEGAHUB est architectur√©e en **4 apps sp√©cialis√©es** suivant le principe de responsabilit√© unique, permettant une gestion compl√®te des jobs IA avec monitoring, quotas et **support natif O3/GPT-4.1**.

### üöÄ Nouveaut√©s 2024
- ‚úÖ **Support O3 complet** : Mod√®les de raisonnement avanc√© avec auto-configuration
- ‚úÖ **GPT-4.1 Enhanced** : Version am√©lior√©e de GPT-4 avec contexte large
- ‚úÖ **Auto-configuration intelligente** : Param√®tres adapt√©s automatiquement selon le mod√®le
- ‚úÖ **Cost optimization** : Recommandations intelligentes par complexit√© de t√¢che
- ‚úÖ **Quality metrics** : M√©triques de performance par g√©n√©ration
- ‚úÖ **Model comparison** : Analytics comparatifs O3 vs legacy

### Base URLs
```
https://backoffice.humari.fr/ai/                 # Hub principal
https://backoffice.humari.fr/ai/providers/       # Providers et credentials
https://backoffice.humari.fr/ai/openai/          # OpenAI O3/GPT-4.1
https://backoffice.humari.fr/ai/usage/           # Usage et m√©triques
```

---

## üìÅ Architecture des Apps

### üéØ ai_core - Hub Central
**Responsabilit√©** : Hub central des jobs IA, types de jobs, statuts
- CRUD des jobs IA principales
- Types de jobs et cat√©gories  
- Statuts et workflow de progression
- **Nouveau** : Support m√©tadonn√©es O3/GPT-4.1
- Dashboard central avec m√©triques cross-providers

[üìñ Documentation Compl√®te](./core.md)

### üîå ai_providers - Providers & Quotas  
**Responsabilit√©** : Gestion providers, credentials s√©curis√©es, quotas
- Providers IA disponibles (OpenAI, Anthropic, Google)
- Credentials chiffr√©es par company avec Fernet
- Quotas et limites par provider
- **Nouveau** : Quotas sp√©cialis√©s O3 (co√ªt √©lev√©)
- Test de connexion et monitoring health

[üìñ Documentation Compl√®te](./providers.md)

### üü¢ ai_openai - OpenAI Integration (O3 Enhanced)
**Responsabilit√©** : Int√©gration sp√©cialis√©e OpenAI multi-g√©n√©ration
- **Support O3/O3-mini** : Mod√®les de raisonnement avec `reasoning_effort`
- **Support GPT-4.1** : Version enhanced avec temp√©rature cr√©ative
- **Auto-configuration** : Param√®tres adapt√©s par mod√®le automatiquement
- **Cost tracking** : Co√ªts pr√©cis par g√©n√©ration avec alertes
- Chat completions unifi√©es et assistants avanc√©s
- **Conversion intelligente** : Messages legacy ‚Üí structured automatique

[üìñ Documentation Compl√®te](./openai.md)

### üìä ai_usage - Usage & Alertes (Enhanced)
**Responsabilit√©** : Tracking usage, co√ªts, m√©triques, alertes
- Usage d√©taill√© par job et provider avec pr√©cision 6 d√©cimales
- **Nouveau** : M√©triques qualit√© O3 vs legacy
- **Nouveau** : Comparaison performance mod√®les avec ROI
- Syst√®me d'alertes quota/budget enhanced
- Analytics et recommandations automatiques
- Export CSV/Excel avec filtres avanc√©s

[üìñ Documentation Compl√®te](./usage.md)

---

## üîë Authentification

**Toutes les APIs** requi√®rent :
```bash
Authorization: Bearer {jwt_token}
X-Brand-ID: {brand_id}  # Scope automatique par brand
```

**Brand Middleware** : Le syst√®me utilise automatiquement `request.current_brand` depuis le middleware, plus besoin de g√©rer manuellement les headers de brand.

---

## üöÄ Quick Start O3

### 1. Chat Completion O3 Simple
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "Analyse ce contenu marketing de fa√ßon approfondie"}
  ],
  "model": "o3",
  "reasoning_effort": "high",
  "max_completion_tokens": 2000
}
```

### 2. O3-Mini pour Optimisation Co√ªt
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "R√©sume cet article SEO"}
  ],
  "model": "o3-mini",
  "reasoning_effort": "medium",
  "max_completion_tokens": 500
}
```

### 3. GPT-4.1 pour Cr√©ativit√©
```bash
POST /ai/openai/chat/
{
  "messages": [
    {"role": "user", "content": "√âcris un article de blog engageant sur l'IA"}
  ],
  "model": "gpt-4.1",
  "temperature": 1.0,
  "max_completion_tokens": 5000
}
```

### 4. Recommandation Automatique
```bash
POST /ai/openai/recommend_model/
{
  "task_description": "Analyser 20 pages de contenu technique",
  "complexity_score": 0.8,
  "budget_constraint": 0.6,
  "quality_requirement": 0.9
}
```

---

## üéØ Endpoints Rapides

### Jobs IA de Base
```http
GET    /ai/jobs/                    # Liste tous les jobs IA
POST   /ai/jobs/                    # Cr√©er nouveau job IA
GET    /ai/jobs/{id}/               # D√©tail job IA
POST   /ai/jobs/{id}/cancel/        # Annuler job
GET    /ai/jobs/dashboard/          # Dashboard jobs IA
GET    /ai/job-types/               # Types de jobs disponibles
```

### OpenAI O3/GPT-4.1
```http
GET    /ai/openai/chat/             # üÜï Mod√®les avec sp√©cificit√©s
POST   /ai/openai/chat/             # üÜï Chat universal multi-mod√®les
GET    /ai/openai/jobs/             # Jobs OpenAI avec m√©triques
GET    /ai/openai/completion/job_result/?job_id=xyz  # R√©sultat job
POST   /ai/openai/recommend_model/  # üÜï Recommandation intelligente
```

### Usage & Analytics Enhanced
```http
GET    /ai/usage/dashboard/?days=7  # Dashboard usage
GET    /ai/usage/model_comparison/  # üÜï Comparaison O3 vs legacy
GET    /ai/usage/cost_breakdown/    # Breakdown co√ªts d√©taill√©
GET    /ai/usage/efficiency/        # üÜï Analyse d'efficacit√© mod√®les
GET    /ai/usage/trends/            # üÜï Tendances temporelles
GET    /ai/alerts/                  # Alertes usage
```

### Providers & Credentials
```http
GET    /ai/providers/               # Providers disponibles
GET    /ai/credentials/quota_status/?provider=openai  # Statut quota
POST   /ai/credentials/test_connection/  # Tester connexion
GET    /ai/providers/health/        # üÜï Health check providers
```

---

## üìà Workflow Typique O3

### 1. Analyse Complexe avec O3
```bash
# √âtape 1: Cr√©er job d'analyse
POST /ai/openai/chat/
{
  "model": "o3",
  "reasoning_effort": "high",
  "messages": [
    {
      "role": "developer", 
      "content": [{"type": "text", "text": "Tu es un expert SEO"}]
    },
    {
      "role": "user",
      "content": [{"type": "text", "text": "Analyse approfondie de ce site..."}]
    }
  ],
  "max_completion_tokens": 3000
}

# √âtape 2: Suivre progression (si async)
GET /ai/jobs/{id}/

# √âtape 3: R√©cup√©rer r√©sultat
GET /ai/openai/completion/job_result/?job_id=ai_job_abc123
```

### 2. Optimisation Co√ªt avec O3-Mini
```bash
# M√™me workflow mais mod√®le optimis√©
POST /ai/openai/chat/
{
  "model": "o3-mini",
  "reasoning_effort": "medium",  # Plus rapide
  "max_completion_tokens": 1000  # Limit√© pour co√ªt
}
```

### 3. Monitoring et Optimisation
```bash
# Analyser usage par mod√®le
GET /ai/usage/model_comparison/?models=o3,o3-mini,gpt-4o&days=30

# V√©rifier co√ªts O3
GET /ai/usage/cost_breakdown/?model=o3

# Alertes budget
GET /ai/alerts/active/
```

---

## üÜï Nouvelles Fonctionnalit√©s

### Auto-Configuration Mod√®les
- **D√©tection automatique** : Legacy vs nouvelle g√©n√©ration
- **Param√®tres optimaux** : Configur√©s selon le mod√®le
- **Conversion intelligente** : Messages et param√®tres adapt√©s
- **Validation** : Erreurs claires sur param√®tres incompatibles

### M√©triques de Qualit√©
```json
{
  "model": "o3",
  "quality_indicators": {
    "reasoning_steps": 47,
    "confidence_score": 0.95,
    "complexity_handled": 0.92
  },
  "performance_profile": {
    "speed": "slow",
    "quality": "highest", 
    "cost": "high"
  }
}
```

### Recommandations Intelligentes
- **S√©lection automatique** selon task complexity
- **Optimisation co√ªt** avec alternatives
- **Benchmarks performance** par use case
- **ROI analysis** O3 vs mod√®les classiques

---

## üîç Filtres Avanc√©s

### Filtres Cross-Apps
```http
# Jobs par statut et provider avec g√©n√©ration
GET /ai/jobs/?status=completed&openai_job__model=o3&openai_job__generation=new

# Usage par p√©riode et co√ªt avec mod√®le sp√©cifique
GET /ai/usage/?created_at__gte=2024-01-01&total_cost__gte=1.00&model_name=o3

# Jobs avec m√©triques sp√©cifiques O3
GET /ai/jobs/?usage__execution_time_seconds__gte=60&openai_job__reasoning_effort=high
```

### Filtres Sp√©cifiques O3
```http
# Jobs par g√©n√©ration
GET /ai/jobs/?openai_job__generation=new&openai_job__reasoning_effort=high

# Usage par co√ªt et efficacit√©
GET /ai/usage/?model_name=o3&total_cost__gte=1.00&cost_efficiency__gte=0.8

# Comparaison performance
GET /ai/usage/?generation=new&quality_score__gte=9.0
```

### Recherche Multi-Crit√®res
```http
GET /ai/openai/jobs/?generation=new&cost_usd__gte=0.5&quality_score__gte=9.0
GET /ai/usage/?search=analysis&model_name__in=o3,o3-mini,gpt-4.1
```

---

## üìä Dashboard Enhanced

### M√©triques O3 vs Legacy
```json
{
  "generation_comparison": {
    "new_models": {
      "models": ["o3", "o3-mini", "gpt-4.1"],
      "avg_quality": 9.2,
      "avg_cost": "0.087",
      "avg_execution_time": 4.8,
      "use_cases": ["complex_analysis", "reasoning", "creative_large_context"]
    },
    "legacy_models": {
      "models": ["gpt-4o", "gpt-4-turbo"],
      "avg_quality": 8.7,
      "avg_cost": "0.023",
      "avg_execution_time": 2.1,
      "use_cases": ["general", "speed_optimized", "cost_effective"]
    }
  },
  "recommendations": {
    "cost_optimization": "Use O3-mini for 80% reasoning tasks",
    "quality_premium": "Reserve O3 for complex analysis only",
    "balanced_approach": "GPT-4.1 for creative + large context",
    "default_choice": "GPT-4o for general purpose tasks"
  }
}
```

### Dashboard Usage avec O3
```json
{
  "period": {"days": 30},
  "totals": {
    "jobs": 1247,
    "cost": "456.78",
    "avg_cost_per_job": "0.367"
  },
  "by_generation": [
    {
      "generation": "new",
      "models": ["o3", "o3-mini", "gpt-4.1"],
      "jobs": 234,
      "cost": "298.45",
      "percentage": 65.3,
      "avg_quality": 9.1
    },
    {
      "generation": "legacy", 
      "models": ["gpt-4o", "gpt-4-turbo"],
      "jobs": 1013,
      "cost": "158.33",
      "percentage": 34.7,
      "avg_quality": 8.6
    }
  ],
  "efficiency_insights": {
    "most_cost_effective": "o3-mini",
    "highest_roi": "o3-mini",
    "premium_choice": "o3",
    "fastest": "gpt-4o"
  }
}
```

---

## üö® Gestion d'Erreurs Enhanced

### Codes de Statut Standards
- **200**: Succ√®s
- **201**: Cr√©ation r√©ussie  
- **400**: Validation √©chou√©e (param√®tres incompatibles)
- **401**: Non authentifi√©
- **403**: Permissions insuffisantes / Quota d√©pass√©
- **404**: Ressource non trouv√©e
- **429**: Rate limit d√©pass√© (O3 sp√©cifique)
- **500**: Erreur serveur

### Erreurs Sp√©cifiques O3
```json
// Temperature sur O3
{
  "error": "O3 models don't support temperature parameter",
  "error_code": "INVALID_PARAMETER_FOR_MODEL",
  "model": "o3",
  "invalid_params": ["temperature"],
  "suggested_params": ["reasoning_effort", "max_completion_tokens"],
  "model_requirements": {
    "required": ["reasoning_effort"],
    "forbidden": ["temperature"],
    "optional": ["max_completion_tokens", "tools"]
  }
}

// Reasoning effort sur legacy
{
  "error": "Model gpt-4o doesn't support reasoning_effort parameter",
  "error_code": "INVALID_PARAMETER_FOR_MODEL", 
  "model": "gpt-4o",
  "invalid_params": ["reasoning_effort"],
  "suggested_params": ["temperature", "max_tokens"]
}

// Budget O3 d√©pass√©
{
  "error": "Estimated cost exceeds daily O3 budget limit",
  "error_code": "O3_BUDGET_EXCEEDED",
  "model": "o3",
  "estimated_cost": "5.67",
  "daily_budget_remaining": "2.34",
  "suggestions": [
    "Use o3-mini for cost optimization",
    "Reduce max_completion_tokens",
    "Use reasoning_effort='low'"
  ],
  "alternatives": ["o3-mini", "gpt-4.1"]
}

// Quota reasoning O3
{
  "error": "Daily reasoning quota exceeded for O3",
  "error_code": "REASONING_QUOTA_EXCEEDED",
  "model": "o3",
  "daily_reasoning_jobs": 50,
  "daily_limit": 50,
  "reset_time": "2024-12-21T00:00:00Z",
  "alternatives": ["o3-mini", "gpt-4.1"]
}
```

### Format d'Erreurs Standard
```json
{
  "detail": "Job type 'invalid_type' non trouv√©",
  "error_code": "JOB_TYPE_NOT_FOUND",
  "field_errors": {
    "job_type": ["Ce champ est requis"],
    "priority": ["Doit √™tre: low, normal, high, urgent"]
  },
  "suggestions": ["chat_completion", "content_analysis", "text_generation"]
}
```

---

## üìñ Documentation D√©taill√©e

- **[üéØ ai_core](./core.md)** - Hub central des jobs IA
- **[üîå ai_providers](./providers.md)** - Providers et credentials s√©curis√©es  
- **[üü¢ ai_openai](./openai.md)** - Int√©gration OpenAI O3/GPT-4.1
- **[üìä ai_usage](./usage.md)** - Usage, m√©triques et alertes enhanced
- **[üìã R√©f√©rence Compl√®te](./complete-reference.md)** - Tous les endpoints O3
- **[üöÄ Exemples](./examples/workflows.md)** - Workflows O3 d'int√©gration
- **[‚öôÔ∏è Migration Guide](./migration/o3-upgrade.md)** - Guide migration O3

---

## üîß Setup et Maintenance

### Variables d'Environnement
```bash
# AI Core
AI_DEFAULT_MODEL=gpt-4o
AI_ENABLE_O3=true
AI_O3_DAILY_BUDGET=100.00

# Encryption
AI_ENCRYPTION_KEY=base64_encoded_key

# Quotas
AI_DEFAULT_MONTHLY_QUOTA=1000000
AI_O3_SPECIAL_QUOTA=50000

# Monitoring
AI_ENABLE_ALERTING=true
AI_ALERT_EMAIL=admin@megahub.fr
```

### Commandes de Gestion
```bash
# Setup complet infrastructure AI
python manage.py setup_ai_infrastructure --include-o3

# Test endpoints API avec O3
python manage.py test_ai_endpoints --test-o3 --verbose

# Setup job types avec support O3
python manage.py setup_ai_job_types --include-o3

# Migration vers O3
python manage.py migrate_to_o3_support

# Health check complet
python manage.py ai_health_check --all-providers

# Reset quotas mensuels
python manage.py reset_monthly_ai_quotas

# Audit credentials
python manage.py audit_ai_credentials --rotate-expired
```

### Tests d'Int√©gration
```bash
# Test suite compl√®te
python manage.py test ai_core ai_providers ai_openai ai_usage

# Test sp√©cifique O3
python manage.py test ai_openai.tests.test_o3_integration

# Load testing
python manage.py ai_load_test --model=o3 --concurrent=10
```

---

## üí° Bonnes Pratiques

### S√©lection de Mod√®le Optimal
1. **O3** : Analyse complexe, recherche approfondie, raisonnement critique
2. **O3-mini** : Raisonnement standard, optimisation co√ªt/qualit√©
3. **GPT-4.1** : Contenu cr√©atif, contexte large, brainstorming
4. **GPT-4o** : T√¢ches g√©n√©rales, rapidit√©, efficacit√© co√ªt

### Optimisation des Co√ªts O3
1. **reasoning_effort='low'** pour t√¢ches simples de raisonnement
2. **Batch processing** pour r√©duire les co√ªts fixes
3. **Cache intelligent** pour requ√™tes similaires  
4. **Fallback strategy** : O3 ‚Üí O3-mini ‚Üí GPT-4.1 ‚Üí GPT-4o
5. **Budget monitoring** : Alertes √† 80% du quota quotidien

### Performance et Monitoring
1. **Tracking par g√©n√©ration** pour analyser ROI pr√©cis
2. **Alertes pr√©ventives** sur cost spikes O3
3. **Quality metrics** pour justifier surco√ªt premium
4. **Usage patterns** pour optimisation continue
5. **A/B testing** mod√®les sur t√¢ches similaires

### S√©curit√©
1. **Rotation credentials** tous les 3 mois minimum
2. **Chiffrement Fernet** pour toutes les cl√©s API
3. **Audit trail** complet des jobs sensibles
4. **Rate limiting** sp√©cialis√© par mod√®le O3
5. **Isolation company** stricte avec middleware

### D√©veloppement
1. **Feature flags** pour rollout progressif O3
2. **Backward compatibility** maintenue legacy models
3. **Testing exhaustif** avant production O3
4. **Monitoring alertes** post-d√©ploiement
5. **Documentation** tenue √† jour avec exemples

---

## üîÆ Roadmap

### Q1 2025
- ‚úÖ Support O3/O3-mini complet
- ‚úÖ Auto-configuration intelligente
- ‚úÖ M√©triques qualit√© avanc√©es
- üîÑ Fine-tuning automatique selon usage
- üîÑ Multi-provider fallback intelligent

### Q2 2025
- üìã Support Anthropic Claude-4 (si disponible)
- üìã Int√©gration Google Gemini Ultra
- üìã Cache distribut√© Redis pour r√©sultats similaires
- üìã API GraphQL pour queries complexes
- üìã Webhooks pour notifications temps r√©el

### Q3 2025
- üìã ML-powered cost prediction
- üìã Auto-scaling workers selon charge
- üìã Custom models fine-tun√©s MEGAHUB
- üìã Analytics pr√©dictifs ROI
- üìã Integration Slack/Teams notifications

---

## üìä M√©triques de Performance

### Objectifs Infrastructure
- **Latence P95** : < 2s pour O3, < 500ms pour legacy
- **Disponibilit√©** : 99.9% uptime
- **Co√ªt par token** : Optimis√© par auto-s√©lection mod√®le
- **Pr√©cision recommandations** : > 90% satisfaction utilisateur
- **S√©curit√©** : 0 breach, rotation automatique cl√©s

### KPIs Business
- **Adoption O3** : 40% des jobs complexes d'ici Q2 2025
- **ROI O3** : Justifi√© par qualit√© sup√©rieure vs co√ªt
- **Cost efficiency** : 25% r√©duction co√ªt total via optimisation
- **User satisfaction** : > 95% sur qualit√© suggestions IA
- **Time to value** : < 5min pour premi√®re completion

---

**Version** : 2.0 - Infrastructure O3 Ready, Production Tested ‚úÖ

**Derni√®re mise √† jour** : D√©cembre 2024 - Support O3/GPT-4.1 complet